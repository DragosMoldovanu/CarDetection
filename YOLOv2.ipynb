{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "another-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.merge import concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "from tqdm import tqdm\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os, cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "specialized-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['Car', 'Van', 'Truck', 'Pedestrian', 'Person_sitting',\n",
    "          'Cyclist', 'Tram', 'Misc', 'DontCare']\n",
    "\n",
    "LABELS = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "          'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "          'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "          'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "          'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "          'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "          'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "          'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "          'hair drier', 'toothbrush']\n",
    "\n",
    "LABELS = ['Pedestrian', 'Cyclist', 'DontCare', 'Car', 'Cyclist', 'DontCare', 'Van', 'Tram', 'Truck', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'Person_sitting', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assisted-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_path = '/Datset/yolov3.weights'\n",
    "train_image_folder = '/Dataset/image_2'\n",
    "train_annot_folder = '/Dataset/label_2'\n",
    "valid_image_folder = '/Dataset/image_2_test'\n",
    "valid_annot_folder = '/Dataset/label_2_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adult-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        with open(weight_file, 'rb') as w_f:\n",
    "            major,    = struct.unpack('i', w_f.read(4))\n",
    "            minor,    = struct.unpack('i', w_f.read(4))\n",
    "            revision, = struct.unpack('i', w_f.read(4))\n",
    "\n",
    "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "                w_f.read(8)\n",
    "            else:\n",
    "                w_f.read(4)\n",
    "\n",
    "            transpose = (major > 1000) or (minor > 1000)\n",
    "            \n",
    "            binary = w_f.read()\n",
    "\n",
    "        self.offset = 0\n",
    "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
    "        \n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    "\n",
    "    def load_weights(self, model):\n",
    "        for i in range(106):\n",
    "            try:\n",
    "                conv_layer = model.get_layer('conv_' + str(i))\n",
    "                print(\"loading weights of convolution #\" + str(i))\n",
    "\n",
    "                if i not in [81, 93, 105]:\n",
    "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
    "\n",
    "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "                    beta  = self.read_bytes(size) # bias\n",
    "                    gamma = self.read_bytes(size) # scale\n",
    "                    mean  = self.read_bytes(size) # mean\n",
    "                    var   = self.read_bytes(size) # variance            \n",
    "\n",
    "                    weights = norm_layer.set_weights([gamma, beta, mean, var])  \n",
    "\n",
    "                if len(conv_layer.get_weights()) > 1:\n",
    "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    \n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2,3,1,0])\n",
    "                    conv_layer.set_weights([kernel, bias])\n",
    "                else:\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2,3,1,0])\n",
    "                    conv_layer.set_weights([kernel])\n",
    "            except ValueError:\n",
    "                print(\"no convolution #\" + str(i))     \n",
    "    \n",
    "    def reset(self):\n",
    "        self.offset = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
