{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "threatened-artwork",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.merge import concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import imgaug as ia\n",
    "from tqdm import tqdm\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os, cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "specialized-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['Pedestrian', 'Cyclist', 'DontCare', 'Car', 'Cyclist', 'DontCare', 'Van', 'Tram', 'Truck', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'Person_sitting', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare', 'DontCare',\n",
    "          'DontCare', 'DontCare']\n",
    "\n",
    "#Let's leave it like this for now and maybe play around with these later\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H, GRID_W = 13, 13\n",
    "BOX = 5\n",
    "CLASS = len(LABELS)\n",
    "CLASS_WEIGHTS = np.ones(CLASS, dtype=\"float32\")\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "WARM_UP_BATCHES = 0\n",
    "TRUE_BOX_BUFFER = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "assisted-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_path = 'VocDataset/yolov1.weights'\n",
    "train_image_folder = 'VocDataset/image_2'\n",
    "train_annot_folder = 'VocDataset/label_2'\n",
    "valid_image_folder = 'VocDataset/image_2_test'\n",
    "valid_annot_folder = 'VocDataset/label_2_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "grand-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_to_depth_x2(x):\n",
    "    return tf.nn.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "suspended-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
    "true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
    "\n",
    "# Layer 1\n",
    "x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "x = BatchNormalization(name='norm_1')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 2\n",
    "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_2')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 3\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_3')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 4\n",
    "x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_4')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 5\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_5')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 6\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_6')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 7\n",
    "x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_7')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 8\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_8')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 9\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_9')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 10\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_10')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 11\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_11')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 12\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_12')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 13\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_13')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "skip_connection = x\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 14\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_14')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 15\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_15')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 16\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_16')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 17\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_17')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 18\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_18')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 19\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_19')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 20\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_20')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 21\n",
    "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "x = concatenate([skip_connection, x])\n",
    "\n",
    "# Layer 22\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_22')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 23\n",
    "x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
    "\n",
    "# small hack to allow true_boxes to be registered when Keras build the model \n",
    "# for more information: https://github.com/fchollet/keras/issues/2790\n",
    "output = Lambda(lambda args: args[0])([output, true_boxes])\n",
    "\n",
    "model = Model([input_image, true_boxes], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "instructional-alert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 416, 416, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 416, 416, 32) 864         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "norm_1 (BatchNormalization)     (None, 416, 416, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_107 (LeakyReLU)     (None, 416, 416, 32) 0           norm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 208, 208, 32) 0           leaky_re_lu_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 208, 208, 64) 18432       max_pooling2d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_2 (BatchNormalization)     (None, 208, 208, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_108 (LeakyReLU)     (None, 208, 208, 64) 0           norm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 104, 104, 64) 0           leaky_re_lu_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 104, 104, 128 73728       max_pooling2d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_3 (BatchNormalization)     (None, 104, 104, 128 512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_109 (LeakyReLU)     (None, 104, 104, 128 0           norm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2D)                 (None, 104, 104, 64) 8192        leaky_re_lu_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_4 (BatchNormalization)     (None, 104, 104, 64) 256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_110 (LeakyReLU)     (None, 104, 104, 64) 0           norm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2D)                 (None, 104, 104, 128 73728       leaky_re_lu_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_5 (BatchNormalization)     (None, 104, 104, 128 512         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_111 (LeakyReLU)     (None, 104, 104, 128 0           norm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 52, 52, 128)  0           leaky_re_lu_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 52, 52, 256)  294912      max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_6 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_112 (LeakyReLU)     (None, 52, 52, 256)  0           norm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_7 (Conv2D)                 (None, 52, 52, 128)  32768       leaky_re_lu_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_7 (BatchNormalization)     (None, 52, 52, 128)  512         conv_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_113 (LeakyReLU)     (None, 52, 52, 128)  0           norm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_8 (Conv2D)                 (None, 52, 52, 256)  294912      leaky_re_lu_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_8 (BatchNormalization)     (None, 52, 52, 256)  1024        conv_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_114 (LeakyReLU)     (None, 52, 52, 256)  0           norm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 26, 26, 256)  0           leaky_re_lu_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_9 (Conv2D)                 (None, 26, 26, 512)  1179648     max_pooling2d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_9 (BatchNormalization)     (None, 26, 26, 512)  2048        conv_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_115 (LeakyReLU)     (None, 26, 26, 512)  0           norm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_10 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_116 (LeakyReLU)     (None, 26, 26, 256)  0           norm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_11 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_11 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_117 (LeakyReLU)     (None, 26, 26, 512)  0           norm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_12 (Conv2D)                (None, 26, 26, 256)  131072      leaky_re_lu_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_12 (BatchNormalization)    (None, 26, 26, 256)  1024        conv_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_118 (LeakyReLU)     (None, 26, 26, 256)  0           norm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_13 (Conv2D)                (None, 26, 26, 512)  1179648     leaky_re_lu_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_13 (BatchNormalization)    (None, 26, 26, 512)  2048        conv_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_119 (LeakyReLU)     (None, 26, 26, 512)  0           norm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling2D) (None, 13, 13, 512)  0           leaky_re_lu_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_14 (Conv2D)                (None, 13, 13, 1024) 4718592     max_pooling2d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "norm_14 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_120 (LeakyReLU)     (None, 13, 13, 1024) 0           norm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_15 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_15 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_121 (LeakyReLU)     (None, 13, 13, 512)  0           norm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_16 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_16 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_122 (LeakyReLU)     (None, 13, 13, 1024) 0           norm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_17 (Conv2D)                (None, 13, 13, 512)  524288      leaky_re_lu_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_17 (BatchNormalization)    (None, 13, 13, 512)  2048        conv_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_123 (LeakyReLU)     (None, 13, 13, 512)  0           norm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_18 (Conv2D)                (None, 13, 13, 1024) 4718592     leaky_re_lu_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_18 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_124 (LeakyReLU)     (None, 13, 13, 1024) 0           norm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_19 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "norm_19 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_21 (Conv2D)                (None, 26, 26, 64)   32768       leaky_re_lu_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_125 (LeakyReLU)     (None, 13, 13, 1024) 0           norm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_21 (BatchNormalization)    (None, 26, 26, 64)   256         conv_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_20 (Conv2D)                (None, 13, 13, 1024) 9437184     leaky_re_lu_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_127 (LeakyReLU)     (None, 26, 26, 64)   0           norm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "norm_20 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 13, 13, 256)  0           leaky_re_lu_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_126 (LeakyReLU)     (None, 13, 13, 1024) 0           norm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 13, 13, 1280) 0           lambda_2[0][0]                   \n",
      "                                                                 leaky_re_lu_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_22 (Conv2D)                (None, 13, 13, 1024) 11796480    concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "norm_22 (BatchNormalization)    (None, 13, 13, 1024) 4096        conv_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_128 (LeakyReLU)     (None, 13, 13, 1024) 0           norm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_23 (Conv2D)                (None, 13, 13, 490)  502250      leaky_re_lu_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 13, 13, 5, 98 0           conv_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 1, 1, 1, 50, 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 13, 13, 5, 98 0           reshape_1[0][0]                  \n",
      "                                                                 input_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 51,050,186\n",
      "Trainable params: 51,029,514\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adult-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import cv2\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, c = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        \n",
    "        self.c     = c\n",
    "        self.classes = classes\n",
    "\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "        \n",
    "        return self.label\n",
    "    \n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "            \n",
    "        return self.score\n",
    "\n",
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        self.offset = 4\n",
    "        self.all_weights = np.fromfile(weight_file, dtype='float32')\n",
    "        \n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.offset = 4\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])  \n",
    "    \n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    \n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    \n",
    "    return float(intersect) / union\n",
    "\n",
    "def draw_boxes(image, boxes, labels):\n",
    "    image_h, image_w, _ = image.shape\n",
    "\n",
    "    for box in boxes:\n",
    "        xmin = int(box.xmin*image_w)\n",
    "        ymin = int(box.ymin*image_h)\n",
    "        xmax = int(box.xmax*image_w)\n",
    "        ymax = int(box.ymax*image_h)\n",
    "\n",
    "        cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (0,255,0), 3)\n",
    "        cv2.putText(image, \n",
    "                    labels[box.get_label()] + ' ' + str(box.get_score()), \n",
    "                    (xmin, ymin - 13), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    1e-3 * image_h, \n",
    "                    (0,255,0), 2)\n",
    "        \n",
    "    return image          \n",
    "        \n",
    "def decode_netout(netout, anchors, nb_class, obj_threshold=0.3, nms_threshold=0.3):\n",
    "    grid_h, grid_w, nb_box = netout.shape[:3]\n",
    "\n",
    "    boxes = []\n",
    "    \n",
    "    # decode the output by the network\n",
    "    netout[..., 4]  = _sigmoid(netout[..., 4])\n",
    "    netout[..., 5:] = netout[..., 4][..., np.newaxis] * _softmax(netout[..., 5:])\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_threshold\n",
    "    \n",
    "    for row in range(grid_h):\n",
    "        for col in range(grid_w):\n",
    "            for b in range(nb_box):\n",
    "                # from 4th element onwards are confidence and class classes\n",
    "                classes = netout[row,col,b,5:]\n",
    "                \n",
    "                if np.sum(classes) > 0:\n",
    "                    # first 4 elements are x, y, w, and h\n",
    "                    x, y, w, h = netout[row,col,b,:4]\n",
    "\n",
    "                    x = (col + _sigmoid(x)) / grid_w # center position, unit: image width\n",
    "                    y = (row + _sigmoid(y)) / grid_h # center position, unit: image height\n",
    "                    w = anchors[2 * b + 0] * np.exp(w) / grid_w # unit: image width\n",
    "                    h = anchors[2 * b + 1] * np.exp(h) / grid_h # unit: image height\n",
    "                    confidence = netout[row,col,b,4]\n",
    "                    \n",
    "                    box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, confidence, classes)\n",
    "                    \n",
    "                    boxes.append(box)\n",
    "\n",
    "    # suppress non-maximal boxes\n",
    "    for c in range(nb_class):\n",
    "        sorted_indices = list(reversed(np.argsort([box.classes[c] for box in boxes])))\n",
    "\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "            \n",
    "            if boxes[index_i].classes[c] == 0: \n",
    "                continue\n",
    "            else:\n",
    "                for j in range(i+1, len(sorted_indices)):\n",
    "                    index_j = sorted_indices[j]\n",
    "                    \n",
    "                    if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_threshold:\n",
    "                        boxes[index_j].classes[c] = 0\n",
    "                        \n",
    "    # remove the boxes which are less likely than a obj_threshold\n",
    "    boxes = [box for box in boxes if box.get_score() > obj_threshold]\n",
    "    \n",
    "    return boxes    \n",
    "\n",
    "def compute_overlap(a, b):\n",
    "    \"\"\"\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a: (N, 4) ndarray of float\n",
    "    b: (K, 4) ndarray of float\n",
    "    Returns\n",
    "    -------\n",
    "    overlaps: (N, K) ndarray of overlap between boxes and query_boxes\n",
    "    \"\"\"\n",
    "    area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\n",
    "\n",
    "    iw = np.minimum(np.expand_dims(a[:, 2], axis=1), b[:, 2]) - np.maximum(np.expand_dims(a[:, 0], 1), b[:, 0])\n",
    "    ih = np.minimum(np.expand_dims(a[:, 3], axis=1), b[:, 3]) - np.maximum(np.expand_dims(a[:, 1], 1), b[:, 1])\n",
    "\n",
    "    iw = np.maximum(iw, 0)\n",
    "    ih = np.maximum(ih, 0)\n",
    "\n",
    "    ua = np.expand_dims((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), axis=1) + area - iw * ih\n",
    "\n",
    "    ua = np.maximum(ua, np.finfo(float).eps)\n",
    "\n",
    "    intersection = iw * ih\n",
    "\n",
    "    return intersection / ua  \n",
    "    \n",
    "def compute_ap(recall, precision):\n",
    "    \"\"\" Compute the average precision, given the recall and precision curves.\n",
    "    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n",
    "    # Arguments\n",
    "        recall:    The recall curve (list).\n",
    "        precision: The precision curve (list).\n",
    "    # Returns\n",
    "        The average precision as computed in py-faster-rcnn.\n",
    "    \"\"\"\n",
    "    # correct AP calculation\n",
    "    # first append sentinel values at the end\n",
    "    mrec = np.concatenate(([0.], recall, [1.]))\n",
    "    mpre = np.concatenate(([0.], precision, [0.]))\n",
    "\n",
    "    # compute the precision envelope\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "    # to calculate area under PR curve, look for points\n",
    "    # where X axis (recall) changes value\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "    # and sum (\\Delta recall) * prec\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap      \n",
    "        \n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3          \n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def _softmax(x, axis=-1, t=-100.):\n",
    "    x = x - np.max(x)\n",
    "    \n",
    "    if np.min(x) < t:\n",
    "        x = x/np.min(x)*t\n",
    "        \n",
    "    e_x = np.exp(x)\n",
    "    \n",
    "    return e_x / e_x.sum(axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "joint-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_reader = WeightReader(wt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "geological-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_reader.reset()\n",
    "nb_conv = 22\n",
    "\n",
    "for i in range(1, nb_conv + 1):\n",
    "    conv_layer = model.get_layer('conv_' + str(i))\n",
    "    \n",
    "    if i < nb_conv:\n",
    "        norm_layer = model.get_layer('norm_' + str(i))\n",
    "        size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "        \n",
    "        beta = weight_reader.read_bytes(size)\n",
    "        gamma = weight_reader.read_bytes(size)\n",
    "        mean = weight_reader.read_bytes(size)\n",
    "        var = weight_reader.read_bytes(size)\n",
    "        \n",
    "        weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
    "    \n",
    "    if len(conv_layer.get_weights()) > 1:\n",
    "        bias = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        kernel = kernel.transpose([2, 3, 1, 0])\n",
    "        conv_layer.set_weights([kernel, bias])\n",
    "    else:\n",
    "        kernel = weight_reader.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "        kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "        kernel = kernel.transpose([2, 3, 1, 0])\n",
    "        conv_layer.set_weights([kernel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.layers[-4]\n",
    "weights = layer.getW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
